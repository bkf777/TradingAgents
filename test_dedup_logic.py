#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç›´æ¥æµ‹è¯•æ¶ˆæ¯å»é‡é€»è¾‘
æ¨¡æ‹ŸLangGraphçš„traceç»“æ„æ¥éªŒè¯æˆ‘ä»¬çš„å»é‡ç®—æ³•
"""

import sys
from datetime import datetime

# æ·»åŠ é¡¹ç›®è·¯å¾„
sys.path.insert(0, '.')

# æ¨¡æ‹ŸLangChainæ¶ˆæ¯å¯¹è±¡
class MockMessage:
    def __init__(self, msg_type, content):
        self.type = msg_type
        self.content = content

def simulate_langgraph_trace():
    """æ¨¡æ‹ŸLangGraphçš„traceç»“æ„ï¼Œå±•ç¤ºæ¶ˆæ¯ç´¯ç§¯çš„é—®é¢˜"""
    
    # æ¨¡æ‹ŸLangGraphçš„traceï¼Œæ¯ä¸ªæ­¥éª¤åŒ…å«ç´¯ç§¯çš„æ¶ˆæ¯
    trace = [
        # ç¬¬1æ­¥ï¼šåˆå§‹æ¶ˆæ¯
        {
            "messages": [
                MockMessage("human", "åˆ†æAAPLè‚¡ç¥¨"),
            ]
        },
        # ç¬¬2æ­¥ï¼šç´¯ç§¯äº†å‰é¢çš„æ¶ˆæ¯ + æ–°æ¶ˆæ¯
        {
            "messages": [
                MockMessage("human", "åˆ†æAAPLè‚¡ç¥¨"),  # é‡å¤
                MockMessage("ai", "æˆ‘æ¥åˆ†æAAPLçš„å¸‚åœºæ•°æ®..."),
            ]
        },
        # ç¬¬3æ­¥ï¼šç´¯ç§¯äº†å‰é¢çš„æ¶ˆæ¯ + æ–°æ¶ˆæ¯
        {
            "messages": [
                MockMessage("human", "åˆ†æAAPLè‚¡ç¥¨"),  # é‡å¤
                MockMessage("ai", "æˆ‘æ¥åˆ†æAAPLçš„å¸‚åœºæ•°æ®..."),  # é‡å¤
                MockMessage("ai", "æ ¹æ®æŠ€æœ¯åˆ†æï¼ŒAAPLæ˜¾ç¤ºå‡º..."),
            ]
        },
        # ç¬¬4æ­¥ï¼šç´¯ç§¯äº†å‰é¢çš„æ¶ˆæ¯ + æ–°æ¶ˆæ¯
        {
            "messages": [
                MockMessage("human", "åˆ†æAAPLè‚¡ç¥¨"),  # é‡å¤
                MockMessage("ai", "æˆ‘æ¥åˆ†æAAPLçš„å¸‚åœºæ•°æ®..."),  # é‡å¤
                MockMessage("ai", "æ ¹æ®æŠ€æœ¯åˆ†æï¼ŒAAPLæ˜¾ç¤ºå‡º..."),  # é‡å¤
                MockMessage("ai", "ç»¼åˆè€ƒè™‘å„é¡¹å› ç´ ï¼Œå»ºè®®..."),
            ]
        },
    ]
    
    return trace

def extract_messages_old_way(trace):
    """æ—§çš„æå–æ–¹å¼ï¼ˆä¼šäº§ç”Ÿé‡å¤ï¼‰"""
    ai_messages = []
    
    for step_idx, step in enumerate(trace):
        if "messages" in step and step["messages"]:
            for msg_idx, msg in enumerate(step["messages"]):
                if hasattr(msg, "content") and hasattr(msg, "type"):
                    ai_messages.append(
                        {
                            "type": msg.type,
                            "content": str(msg.content),
                            "step_index": step_idx,
                            "message_index": msg_idx,
                        }
                    )
    
    return ai_messages

def extract_messages_new_way(trace):
    """æ–°çš„æå–æ–¹å¼ï¼ˆé¿å…é‡å¤ï¼‰"""
    ai_messages = []
    processed_messages = set()
    
    for step_idx, step in enumerate(trace):
        if "messages" in step and step["messages"]:
            current_messages = step["messages"]
            
            # å¦‚æœæ˜¯ç¬¬ä¸€æ­¥ï¼Œæ‰€æœ‰æ¶ˆæ¯éƒ½æ˜¯æ–°çš„
            if step_idx == 0:
                new_messages = current_messages
            else:
                # è·å–ä¸Šä¸€æ­¥çš„æ¶ˆæ¯æ•°é‡
                prev_step = trace[step_idx - 1]
                prev_msg_count = len(prev_step.get("messages", []))
                # åªå–æ–°å¢çš„æ¶ˆæ¯
                new_messages = current_messages[prev_msg_count:]
            
            # å¤„ç†æ–°å¢çš„æ¶ˆæ¯
            for msg_idx, msg in enumerate(new_messages):
                if hasattr(msg, "content") and hasattr(msg, "type"):
                    # åˆ›å»ºæ¶ˆæ¯çš„å”¯ä¸€æ ‡è¯†ç¬¦
                    msg_id = f"{step_idx}_{len(current_messages) - len(new_messages) + msg_idx}_{hash(str(msg.content))}"
                    
                    if msg_id not in processed_messages:
                        processed_messages.add(msg_id)
                        ai_messages.append(
                            {
                                "type": msg.type,
                                "content": str(msg.content),
                                "step_index": step_idx,
                                "message_index": len(current_messages) - len(new_messages) + msg_idx,
                            }
                        )
    
    return ai_messages

def analyze_messages(messages, method_name):
    """åˆ†ææ¶ˆæ¯åˆ—è¡¨ï¼Œæ£€æŸ¥é‡å¤æƒ…å†µ"""
    print(f"\nğŸ“Š {method_name} ç»“æœåˆ†æ:")
    print(f"  - æ€»æ¶ˆæ¯æ•°é‡: {len(messages)}")
    
    # æŒ‰å†…å®¹åˆ†ç»„ï¼Œæ£€æŸ¥é‡å¤
    content_counts = {}
    for msg in messages:
        content = msg["content"]
        content_counts[content] = content_counts.get(content, 0) + 1
    
    # ç»Ÿè®¡é‡å¤æƒ…å†µ
    unique_contents = len(content_counts)
    duplicate_contents = [content for content, count in content_counts.items() if count > 1]
    
    print(f"  - å”¯ä¸€å†…å®¹æ•°é‡: {unique_contents}")
    print(f"  - é‡å¤å†…å®¹æ•°é‡: {len(duplicate_contents)}")
    
    if duplicate_contents:
        print(f"  âš ï¸ é‡å¤çš„å†…å®¹:")
        for content in duplicate_contents:
            count = content_counts[content]
            print(f"    - \"{content[:50]}...\" (å‡ºç°{count}æ¬¡)")
    else:
        print(f"  âœ… æ²¡æœ‰é‡å¤å†…å®¹")
    
    # æ˜¾ç¤ºæ¶ˆæ¯è¯¦æƒ…
    print(f"  ğŸ“ æ¶ˆæ¯è¯¦æƒ…:")
    for i, msg in enumerate(messages, 1):
        print(f"    {i}. æ­¥éª¤{msg['step_index']}, ç´¢å¼•{msg['message_index']}: [{msg['type']}] {msg['content'][:50]}...")
    
    return len(duplicate_contents) == 0

def test_deduplication_logic():
    """æµ‹è¯•å»é‡é€»è¾‘"""
    print("ğŸ§ª æµ‹è¯•æ¶ˆæ¯å»é‡é€»è¾‘")
    print("=" * 60)
    
    # ç”Ÿæˆæ¨¡æ‹Ÿtrace
    trace = simulate_langgraph_trace()
    print(f"ğŸ“‹ æ¨¡æ‹Ÿtraceç»“æ„ (å…±{len(trace)}ä¸ªæ­¥éª¤):")
    for i, step in enumerate(trace):
        msg_count = len(step["messages"])
        print(f"  æ­¥éª¤{i}: {msg_count}æ¡æ¶ˆæ¯")
    
    # æµ‹è¯•æ—§æ–¹æ³•
    print("\n" + "=" * 60)
    old_messages = extract_messages_old_way(trace)
    old_success = analyze_messages(old_messages, "æ—§æ–¹æ³•ï¼ˆä¼šäº§ç”Ÿé‡å¤ï¼‰")
    
    # æµ‹è¯•æ–°æ–¹æ³•
    print("\n" + "=" * 60)
    new_messages = extract_messages_new_way(trace)
    new_success = analyze_messages(new_messages, "æ–°æ–¹æ³•ï¼ˆå»é‡ä¼˜åŒ–ï¼‰")
    
    # æ€»ç»“
    print("\n" + "=" * 60)
    print("ğŸ“Š å¯¹æ¯”æ€»ç»“:")
    print(f"  - æ—§æ–¹æ³•: {len(old_messages)}æ¡æ¶ˆæ¯, {'âœ…æ— é‡å¤' if old_success else 'âŒæœ‰é‡å¤'}")
    print(f"  - æ–°æ–¹æ³•: {len(new_messages)}æ¡æ¶ˆæ¯, {'âœ…æ— é‡å¤' if new_success else 'âŒæœ‰é‡å¤'}")
    
    if new_success and not old_success:
        print("\nğŸ‰ å»é‡é€»è¾‘ä¿®å¤æˆåŠŸï¼æ–°æ–¹æ³•æœ‰æ•ˆæ¶ˆé™¤äº†é‡å¤æ¶ˆæ¯ã€‚")
        return True
    elif new_success and old_success:
        print("\nğŸ¤” ä¸¤ç§æ–¹æ³•éƒ½æ²¡æœ‰é‡å¤ï¼Œå¯èƒ½æµ‹è¯•ç”¨ä¾‹ä¸å¤Ÿå¤æ‚ã€‚")
        return True
    else:
        print("\nâŒ å»é‡é€»è¾‘ä»æœ‰é—®é¢˜ï¼Œéœ€è¦è¿›ä¸€æ­¥ä¼˜åŒ–ã€‚")
        return False

if __name__ == "__main__":
    success = test_deduplication_logic()
    
    print("\n" + "=" * 60)
    if success:
        print("ğŸ‰ å»é‡é€»è¾‘æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("âŒ å»é‡é€»è¾‘æµ‹è¯•å¤±è´¥ã€‚")
